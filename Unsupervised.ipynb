{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## requirement"
      ],
      "metadata": {
        "id": "9uyscYwuG0ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install py_vncorenlp gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-tTsdH66Isa",
        "outputId": "b4ef6b27-ec6d-46e0-d6bd-45411b6367ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py_vncorenlp\n",
            "  Downloading py_vncorenlp-0.1.4.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Collecting pyjnius (from py_vncorenlp)\n",
            "  Downloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Building wheels for collected packages: py_vncorenlp\n",
            "  Building wheel for py_vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py_vncorenlp: filename=py_vncorenlp-0.1.4-py3-none-any.whl size=4307 sha256=7b97e970488728b063a896bdb004435e36b1bb855100a06529da819267b4df41\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/d9/bf/62632cdb007c702a0664091e92a0bb1f18a2fcecbe962d9827\n",
            "Successfully built py_vncorenlp\n",
            "Installing collected packages: pyjnius, py_vncorenlp\n",
            "Successfully installed py_vncorenlp-0.1.4 pyjnius-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import"
      ],
      "metadata": {
        "id": "3c8KW2WcG3c7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbD5KQF_GKgQ"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import math\n",
        "import py_vncorenlp\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataset"
      ],
      "metadata": {
        "id": "YBvYkbmcG5nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown==4.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMFVCZeoyXwc",
        "outputId": "c8155351-01b7-4eb8-cb7e-751626426cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gdown==4.6.0\n",
            "  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==4.6.0) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown==4.6.0) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown==4.6.0) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown==4.6.0) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==4.6.0) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==4.6.0) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.6.0) (2023.11.17)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.6.0) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.7.0\n",
            "    Uninstalling gdown-4.7.0:\n",
            "      Successfully uninstalled gdown-4.7.0\n",
            "Successfully installed gdown-4.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir train\n",
        "!cd train && gdown https://drive.google.com/uc?id=1N41RpBMDfnMyipQUDTXoPvmPdd4ZDPuA&export=download\n",
        "!cd train && gdown https://drive.google.com/uc?id=16fOhp5N2xUSWCPfthUaSpbhtj8zKlCe0&export=download\n",
        "!mkdir test\n",
        "!cd test && gdown https://drive.google.com/uc?id=1jirCj9X_rLSoUFFvQD8RYY5GEC12va4-&export=download\n",
        "!cd test && gdown https://drive.google.com/uc?id=1RSOhUrtvT0A_DMcuugdpPyY2NwKvSK7C&export=download"
      ],
      "metadata": {
        "id": "-bljX-QzG7SE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01bd14c8-a01b-4465-f8e2-82384923ba15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘train’: File exists\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1N41RpBMDfnMyipQUDTXoPvmPdd4ZDPuA\n",
            "To: /content/train/sents.txt\n",
            "100% 898k/898k [00:00<00:00, 42.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16fOhp5N2xUSWCPfthUaSpbhtj8zKlCe0\n",
            "To: /content/train/sentiments.txt\n",
            "100% 22.9k/22.9k [00:00<00:00, 51.6MB/s]\n",
            "mkdir: cannot create directory ‘test’: File exists\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jirCj9X_rLSoUFFvQD8RYY5GEC12va4-\n",
            "To: /content/test/sents.txt\n",
            "100% 248k/248k [00:00<00:00, 92.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RSOhUrtvT0A_DMcuugdpPyY2NwKvSK7C\n",
            "To: /content/test/sentiments.txt\n",
            "100% 6.33k/6.33k [00:00<00:00, 14.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train/sents.txt') as data, open('train/sentiments.txt') as label:\n",
        "  traindata = []\n",
        "  for dataline, labelline in zip(data, label):\n",
        "    sentence = dataline.strip()\n",
        "    sentiment = int(labelline.strip())\n",
        "    if sentiment == 1:\n",
        "      continue\n",
        "    traindata.append((sentence, sentiment))\n",
        "print(len(traindata))\n",
        "traindata[12]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7UsyxeF_kw1",
        "outputId": "be79b5c8-3d8f-41a8-f574-e738055ef887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10968\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('có thể cho sinh viên đi thăm quan nhiều công ty xem quy mô và cách làm việc , để giúp hiểu rõ hơn vê ngành mình đang học .',\n",
              " 0)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test/sents.txt') as data, open('test/sentiments.txt') as label:\n",
        "  testdata = []\n",
        "  for dataline, labelline in zip(data, label):\n",
        "    sentence = dataline.strip()\n",
        "    sentiment = int(labelline.strip())\n",
        "    if sentiment == 1:\n",
        "      continue\n",
        "    testdata.append((sentence, sentiment))\n",
        "print(len(testdata))\n",
        "testdata[79]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M70mhK8p6zHM",
        "outputId": "c4976574-3913-47ca-fc70-658884813214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('nhiệt tình giúp đỡ giải đáp những thắc mắc của sinh viên .', 2)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## phrase"
      ],
      "metadata": {
        "id": "fuOn7tEcLr62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "py_vncorenlp.download_model(save_dir='./')"
      ],
      "metadata": {
        "id": "zL05t3xVG-MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phraseModel = py_vncorenlp.VnCoreNLP(annotators=['wseg', 'pos'], save_dir='./')"
      ],
      "metadata": {
        "id": "5E48E1uM6ZVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getPos(sentence):\n",
        "  annotated = phraseModel.annotate_text(sentence)\n",
        "  words = [word['wordForm'] for word in annotated[0]]\n",
        "  tags = [word['posTag'] for word in annotated[0]]\n",
        "  return words, tags"
      ],
      "metadata": {
        "id": "wvhuVB_a77NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words, tags = getPos(traindata[999][0])\n",
        "print(words)\n",
        "print(tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uekbfbPJ8cJt",
        "outputId": "d99b8abc-c4d9-4fc1-e71b-016ffadc478b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cập_nhật', 'tài_liệu', 'đầy_đủ', 'cho', 'sinh_viên', '!']\n",
            "['V', 'N', 'A', 'E', 'N', 'CH']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getPhrase(words, tags):\n",
        "  phrases = []\n",
        "  ptags = []\n",
        "  for idx, word in enumerate(words):\n",
        "    phrase = tuple(words[idx:idx + 2])\n",
        "    ptag = tuple(tags[idx:idx + 2])\n",
        "    if ptag in [('N', 'A'), ('V', 'A'), ('R', 'A'), ('R', 'V'), ('V', 'R')]:\n",
        "      phrases.append(phrase)\n",
        "      ptags.append(ptag)\n",
        "  return phrases, ptags"
      ],
      "metadata": {
        "id": "16fdSX8G8tlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrases, ptags = getPhrase(words, tags)\n",
        "print(phrases)\n",
        "print(ptags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiEPiq8q9pa-",
        "outputId": "957c154e-815b-4dee-97e1-8a405b629026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('tài_liệu', 'đầy_đủ')]\n",
            "[('N', 'A')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pmi"
      ],
      "metadata": {
        "id": "qLVaadEcG8dA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PMIModel:\n",
        "  def __init__(self, traindata):\n",
        "    self.map1 = {}\n",
        "    self.map2 = {}\n",
        "    posCount = 0\n",
        "    globalCount = 0\n",
        "    for sentence, label in tqdm(traindata):\n",
        "      if label == 2:\n",
        "        posCount += 1\n",
        "      words, tags = getPos(sentence)\n",
        "      phrases, ptags = getPhrase(words, tags)\n",
        "      for p in phrases:\n",
        "        globalCount += 1\n",
        "        self.map1[p] = self.map1.get(p, 0) + 1\n",
        "        p2 = (p, label)\n",
        "        self.map2[p2] = self.map2.get(p2, 0) + 1\n",
        "    print(len(self.map1))\n",
        "    for key, val in self.map1.items():\n",
        "      self.map1[key] = val / globalCount\n",
        "    for key, val in self.map2.items():\n",
        "      self.map2[key] = val / globalCount\n",
        "    self.map1[0] = 1.0 - posCount / len(traindata)\n",
        "    self.map1[2] = posCount / len(traindata)\n",
        "\n",
        "  def getProb(self, p):\n",
        "    return self.map1.get(p, 0.0) + 0.01\n",
        "\n",
        "  def getProb2(self, p1, p2):\n",
        "    return self.map2.get((p1, p2), 0.0) + 0.01\n",
        "\n",
        "  def predict(self, sentence):\n",
        "    words, tags = getPos(sentence)\n",
        "    phrases, ptags = getPhrase(words, tags)\n",
        "    so = 0.0\n",
        "    for p in phrases:\n",
        "      sop2 = self.getProb2(p, 2) / (self.getProb(p) * self.getProb(2))\n",
        "      sop0 = self.getProb2(p, 0) / (self.getProb(p) * self.getProb(0))\n",
        "      so += math.log2(sop2) - math.log2(sop0)\n",
        "    return 2 if so >= 0 else 0\n",
        "\n",
        "  def test(self, dataset):\n",
        "    hitCount = 0\n",
        "    yTrue = []\n",
        "    yPred = []\n",
        "    for sentence, label in tqdm(dataset):\n",
        "      predict = self.predict(sentence)\n",
        "      yTrue.append(label)\n",
        "      yPred.append(predict)\n",
        "      if predict == label:\n",
        "        hitCount += 1\n",
        "    print(f'{hitCount}/{len(dataset)} ~{hitCount / len(dataset) * 100}')\n",
        "    f1Score = f1_score(yTrue, yPred, average='weighted')\n",
        "    print(f'f1 score: {f1Score}')"
      ],
      "metadata": {
        "id": "ABw9uaU2Eh3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pmiModel = PMIModel(traindata)\n",
        "pmiModel.test(testdata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtZSAsIxIOUz",
        "outputId": "06b10f67-9bbf-4695-eea6-49787a5b943c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10968/10968 [00:11<00:00, 984.06it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2999/2999 [00:02<00:00, 1202.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2163/2999 ~72.1240413471157\n",
            "f1 score: 0.7176818017124736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## word2vec"
      ],
      "metadata": {
        "id": "Ms08OSwNG-vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import torch\n",
        "import torch.nn.functional as torchF\n",
        "\n",
        "class W2VModel:\n",
        "  def __init__(self, traindata):\n",
        "    self.sentences = []\n",
        "    for sentence, label in tqdm(traindata):\n",
        "      words, tags = getPos(sentence)\n",
        "      self.sentences.append(words)\n",
        "    self.vectorSize = 100\n",
        "    self.w2v = Word2Vec(sentences=self.sentences, vector_size=self.vectorSize, window=5, min_count=1, workers=2)\n",
        "    print()\n",
        "    print(self.w2v.wv.vectors.shape)\n",
        "\n",
        "  def embed(self, word):\n",
        "    if word in self.w2v.wv.key_to_index:\n",
        "      return torch.Tensor(self.w2v.wv[word])\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "  def embed2(self, phrase):\n",
        "    res = torch.zeros(self.vectorSize)\n",
        "    resLen = 0\n",
        "    for word in phrase:\n",
        "      wres = self.embed(word)\n",
        "      if wres is None:\n",
        "        continue\n",
        "      res += wres\n",
        "      resLen += 1\n",
        "    return res / resLen\n",
        "\n",
        "  def predict(self, sentence):\n",
        "    posEp = self.embed('tốt')\n",
        "    negEp = self.embed('kém')\n",
        "    words, tags = getPos(sentence)\n",
        "    phrases, ptags = getPhrase(words, tags)\n",
        "    so = 0.0\n",
        "    for p in phrases:\n",
        "      ep = self.embed2(p)\n",
        "      posSim = torchF.cosine_similarity(ep, posEp, dim=0)\n",
        "      negSim = torchF.cosine_similarity(ep, negEp, dim=0)\n",
        "      so += posSim - negSim\n",
        "    return 2 if so >= 0 else 0\n",
        "\n",
        "  def test(self, dataset):\n",
        "    hitCount = 0\n",
        "    yTrue = []\n",
        "    yPred = []\n",
        "    for sentence, label in tqdm(dataset):\n",
        "      predict = self.predict(sentence)\n",
        "      yTrue.append(label)\n",
        "      yPred.append(predict)\n",
        "      if predict == label:\n",
        "        hitCount += 1\n",
        "    print(f'{hitCount}/{len(dataset)} ~{hitCount / len(dataset) * 100}')\n",
        "    f1Score = f1_score(yTrue, yPred, average='weighted')\n",
        "    print(f'f1 score: {f1Score}')"
      ],
      "metadata": {
        "id": "RWqpAP1uHAGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2vModel = W2VModel(traindata)\n",
        "w2vModel.test(testdata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FJiHbPbtGEZ",
        "outputId": "da1294ea-dabc-41ff-ccb2-3c7e580f0362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10968/10968 [00:09<00:00, 1147.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(3568, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2999 [00:00<?, ?it/s]<ipython-input-33-d97114ddf32d>:18: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  return torch.Tensor(self.w2v.wv[word])\n",
            "100%|██████████| 2999/2999 [00:03<00:00, 785.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2284/2999 ~76.15871957319106\n",
            "f1 score: 0.76117136121854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## with neutral"
      ],
      "metadata": {
        "id": "EKSzqoQg_nv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train/sents.txt') as data, open('train/sentiments.txt') as label:\n",
        "  traindata = []\n",
        "  for dataline, labelline in zip(data, label):\n",
        "    sentence = dataline.strip()\n",
        "    sentiment = int(labelline.strip())\n",
        "    traindata.append((sentence, sentiment))\n",
        "print(len(traindata))\n",
        "traindata[12]"
      ],
      "metadata": {
        "id": "IAhd363iEpMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd92ae81-1a81-4a21-9a61-3ffeee93a34d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11426\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('đang dạy thầy wzjwz208 đi qua nước ngoài giữa chừng , thầy wzjwz209 dạy thay .',\n",
              " 1)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test/sents.txt') as data, open('test/sentiments.txt') as label:\n",
        "  testdata = []\n",
        "  for dataline, labelline in zip(data, label):\n",
        "    sentence = dataline.strip()\n",
        "    sentiment = int(labelline.strip())\n",
        "    testdata.append((sentence, sentiment))\n",
        "print(len(testdata))\n",
        "testdata[79]"
      ],
      "metadata": {
        "id": "0gu0waWBErH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ebfac0-9ca2-466d-9a37-da349df5936a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3166\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('giảng bài xúc tích .', 2)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PMIModel:\n",
        "  def __init__(self, traindata):\n",
        "    self.map1 = {}\n",
        "    self.map2 = {}\n",
        "    posCount = 0\n",
        "    globalCount = 0\n",
        "    for sentence, label in tqdm(traindata):\n",
        "      if label == 2:\n",
        "        posCount += 1\n",
        "      words, tags = getPos(sentence)\n",
        "      phrases, ptags = getPhrase(words, tags)\n",
        "      for p in phrases:\n",
        "        globalCount += 1\n",
        "        self.map1[p] = self.map1.get(p, 0) + 1\n",
        "        p2 = (p, label)\n",
        "        self.map2[p2] = self.map2.get(p2, 0) + 1\n",
        "    print(len(self.map1))\n",
        "    for key, val in self.map1.items():\n",
        "      self.map1[key] = val / globalCount\n",
        "    for key, val in self.map2.items():\n",
        "      self.map2[key] = val / globalCount\n",
        "    self.map1[0] = 1.0 - posCount / len(traindata)\n",
        "    self.map1[2] = posCount / len(traindata)\n",
        "\n",
        "  def getProb(self, p):\n",
        "    return self.map1.get(p, 0.0) + 0.01\n",
        "\n",
        "  def getProb2(self, p1, p2):\n",
        "    return self.map2.get((p1, p2), 0.0) + 0.01\n",
        "\n",
        "  def predict(self, sentence):\n",
        "    words, tags = getPos(sentence)\n",
        "    phrases, ptags = getPhrase(words, tags)\n",
        "    so = 0.0\n",
        "    for p in phrases:\n",
        "      sop2 = self.getProb2(p, 2) / (self.getProb(p) * self.getProb(2))\n",
        "      sop0 = self.getProb2(p, 0) / (self.getProb(p) * self.getProb(0))\n",
        "      so += math.log2(sop2) - math.log2(sop0)\n",
        "    if abs(so) <= 1e-8:\n",
        "      return 1\n",
        "    return 2 if so >= 0 else 0\n",
        "\n",
        "  def test(self, dataset):\n",
        "    hitCount = 0\n",
        "    yTrue = []\n",
        "    yPred = []\n",
        "    for sentence, label in tqdm(dataset):\n",
        "      predict = self.predict(sentence)\n",
        "      yTrue.append(label)\n",
        "      yPred.append(predict)\n",
        "      if predict == label:\n",
        "        hitCount += 1\n",
        "    print(f'{hitCount}/{len(dataset)} ~{hitCount / len(dataset) * 100}')\n",
        "    f1Score = f1_score(yTrue, yPred, average='weighted')\n",
        "    print(f'f1 score: {f1Score}')"
      ],
      "metadata": {
        "id": "vLgUerFq8rW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pmiModel = PMIModel(traindata)\n",
        "pmiModel.test(testdata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Po1_dnh_qRL",
        "outputId": "33a4eb8e-28b3-4236-ffe0-cf248c393e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11426/11426 [00:11<00:00, 978.03it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3166/3166 [00:02<00:00, 1087.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1952/3166 ~61.65508528111181\n",
            "f1 score: 0.6249543992345439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import torch\n",
        "import torch.nn.functional as torchF\n",
        "\n",
        "class W2VModel:\n",
        "  def __init__(self, traindata):\n",
        "    self.sentences = []\n",
        "    for sentence, label in tqdm(traindata):\n",
        "      words, tags = getPos(sentence)\n",
        "      self.sentences.append(words)\n",
        "    self.vectorSize = 100\n",
        "    self.w2v = Word2Vec(sentences=self.sentences, vector_size=self.vectorSize, window=5, min_count=1, workers=2)\n",
        "    print()\n",
        "    print(self.w2v.wv.vectors.shape)\n",
        "\n",
        "  def embed(self, word):\n",
        "    if word in self.w2v.wv.key_to_index:\n",
        "      return torch.Tensor(self.w2v.wv[word])\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "  def embed2(self, phrase):\n",
        "    res = torch.zeros(self.vectorSize)\n",
        "    resLen = 0\n",
        "    for word in phrase:\n",
        "      wres = self.embed(word)\n",
        "      if wres is None:\n",
        "        continue\n",
        "      res += wres\n",
        "      resLen += 1\n",
        "    return res / resLen if resLen > 0 else res\n",
        "\n",
        "  def predict(self, sentence, posWord='tốt', negWord='kém'):\n",
        "    posEp = self.embed(posWord)\n",
        "    negEp = self.embed(negWord)\n",
        "    words, tags = getPos(sentence)\n",
        "    phrases, ptags = getPhrase(words, tags)\n",
        "    so = 0.0\n",
        "    for p in phrases:\n",
        "      ep = self.embed2(p)\n",
        "      posSim = torchF.cosine_similarity(ep, posEp, dim=0)\n",
        "      negSim = torchF.cosine_similarity(ep, negEp, dim=0)\n",
        "      so += posSim - negSim\n",
        "    if abs(so) <= 1e-8:\n",
        "      return 1\n",
        "    return 2 if so >= 0 else 0\n",
        "\n",
        "  def test(self, dataset, posWord='tốt', negWord='kém'):\n",
        "    hitCount = 0\n",
        "    yTrue = []\n",
        "    yPred = []\n",
        "    for sentence, label in tqdm(dataset):\n",
        "      predict = self.predict(sentence, posWord, negWord)\n",
        "      yTrue.append(label)\n",
        "      yPred.append(predict)\n",
        "      if predict == label:\n",
        "        hitCount += 1\n",
        "    print(f'{hitCount}/{len(dataset)} ~{hitCount / len(dataset) * 100}')\n",
        "    f1Score = f1_score(yTrue, yPred, average='weighted')\n",
        "    print(f'f1 score: {f1Score}')\n",
        "\n",
        "  def predict2(self, sentence, posList=['tốt'], negList=['kém']):\n",
        "    posEp = self.embed2(posList)\n",
        "    negEp = self.embed2(negList)\n",
        "    words, tags = getPos(sentence)\n",
        "    phrases, ptags = getPhrase(words, tags)\n",
        "    so = 0.0\n",
        "    for p in phrases:\n",
        "      ep = self.embed2(p)\n",
        "      posSim = torchF.cosine_similarity(ep, posEp, dim=0)\n",
        "      negSim = torchF.cosine_similarity(ep, negEp, dim=0)\n",
        "      so += posSim - negSim\n",
        "    if abs(so) <= 1e-8:\n",
        "      return 1\n",
        "    return 2 if so >= 0 else 0\n",
        "\n",
        "  def test2(self, dataset, posList=['tốt'], negList=['kém']):\n",
        "    hitCount = 0\n",
        "    yTrue = []\n",
        "    yPred = []\n",
        "    for sentence, label in tqdm(dataset):\n",
        "      predict = self.predict2(sentence, posList, negList)\n",
        "      yTrue.append(label)\n",
        "      yPred.append(predict)\n",
        "      if predict == label:\n",
        "        hitCount += 1\n",
        "    print(f'{hitCount}/{len(dataset)} ~{hitCount / len(dataset) * 100}')\n",
        "    f1Score = f1_score(yTrue, yPred, average='weighted')\n",
        "    print(f'f1 score: {f1Score}')"
      ],
      "metadata": {
        "id": "HlAbnDF_Aebk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2vModel = W2VModel(traindata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbLyvKZyzfr1",
        "outputId": "616685e4-51b6-4740-d04e-ba8e675e6ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11426/11426 [00:17<00:00, 664.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(3655, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2vModel.test2(testdata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5uxD-pxzrj2",
        "outputId": "08ddecc7-5139-435f-c74f-4aab40f4af26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3166/3166 [00:06<00:00, 515.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2131/3166 ~67.30890713834492\n",
            "f1 score: 0.696228041215839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2vModel.test2(testdata, ['hay'], ['tệ'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm73Q9oQ4Vh-",
        "outputId": "5db59137-bbeb-46ec-c6ce-8f606420d8da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3166/3166 [00:05<00:00, 536.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2090/3166 ~66.01389766266583\n",
            "f1 score: 0.6851564698764465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2vModel.test2(testdata, ['vui'], ['chán'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij-fePNNzf4H",
        "outputId": "55e2bbe5-8319-4aad-84d9-d0c6cd6920be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3166/3166 [00:09<00:00, 323.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2170/3166 ~68.54074542008844\n",
            "f1 score: 0.711130145033557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2vModel.test2(testdata, ['dễ'], ['khó'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTBRBbVw0G-o",
        "outputId": "49a98c3a-c639-463a-f028-96d87cee7725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3166/3166 [00:08<00:00, 388.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2142/3166 ~67.65634870499052\n",
            "f1 score: 0.7025567395284235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2vModel.test2(testdata, ['tốt', 'hay', 'vui', 'dễ'], ['xấu', 'chán', 'khó', 'tệ'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CXBkCeh2E-i",
        "outputId": "1f47d680-4bd3-4705-9903-d6714643b755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3166/3166 [00:04<00:00, 656.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2204/3166 ~69.61465571699304\n",
            "f1 score: 0.7243333938062507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z_lWH6lw5CUR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}