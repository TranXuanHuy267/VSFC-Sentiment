{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## requirement"
      ],
      "metadata": {
        "id": "9uyscYwuG0ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install py_vncorenlp gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-tTsdH66Isa",
        "outputId": "9bdf5ce8-f96a-4855-9ac1-cbf48b2421e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py_vncorenlp\n",
            "  Downloading py_vncorenlp-0.1.4.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Collecting pyjnius (from py_vncorenlp)\n",
            "  Downloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Building wheels for collected packages: py_vncorenlp\n",
            "  Building wheel for py_vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py_vncorenlp: filename=py_vncorenlp-0.1.4-py3-none-any.whl size=4307 sha256=59e1cb37afb27ddd160810c7e0df02f946913ba3733ead541d8f16a50d8bc1d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/d9/bf/62632cdb007c702a0664091e92a0bb1f18a2fcecbe962d9827\n",
            "Successfully built py_vncorenlp\n",
            "Installing collected packages: pyjnius, py_vncorenlp\n",
            "Successfully installed py_vncorenlp-0.1.4 pyjnius-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import"
      ],
      "metadata": {
        "id": "3c8KW2WcG3c7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbD5KQF_GKgQ"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import math\n",
        "import py_vncorenlp\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataset"
      ],
      "metadata": {
        "id": "YBvYkbmcG5nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir train\n",
        "!cd train && gdown https://drive.google.com/uc?id=1nzak5OkrheRV1ltOGCXkT671bmjODLhP&export=download\n",
        "!cd train && gdown https://drive.google.com/uc?id=1ye-gOZIBqXdKOoi_YxvpT6FeRNmViPPv&export=download\n",
        "!mkdir test\n",
        "!cd test && gdown https://drive.google.com/uc?id=1aNMOeZZbNwSRkjyCWAGtNCMa3YrshR-n&export=download\n",
        "!cd test && gdown https://drive.google.com/uc?id=1vkQS5gI0is4ACU58-AbWusnemw7KZNfO&export=download"
      ],
      "metadata": {
        "id": "-bljX-QzG7SE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f52e671-209e-49ea-f6c2-58187b957ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nzak5OkrheRV1ltOGCXkT671bmjODLhP\n",
            "To: /content/train/sents.txt\n",
            "100% 898k/898k [00:00<00:00, 100MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ye-gOZIBqXdKOoi_YxvpT6FeRNmViPPv\n",
            "To: /content/train/sentiments.txt\n",
            "100% 22.9k/22.9k [00:00<00:00, 35.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1aNMOeZZbNwSRkjyCWAGtNCMa3YrshR-n\n",
            "To: /content/test/sents.txt\n",
            "100% 248k/248k [00:00<00:00, 35.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vkQS5gI0is4ACU58-AbWusnemw7KZNfO\n",
            "To: /content/test/sentiments.txt\n",
            "100% 6.33k/6.33k [00:00<00:00, 2.43MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train/sents.txt') as data, open('train/sentiments.txt') as label:\n",
        "  traindata = []\n",
        "  for dataline, labelline in zip(data, label):\n",
        "    sentence = dataline.strip()\n",
        "    sentiment = int(labelline.strip())\n",
        "    if sentiment == 1:\n",
        "      continue\n",
        "    traindata.append((sentence, sentiment))\n",
        "print(len(traindata))\n",
        "traindata[12]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7UsyxeF_kw1",
        "outputId": "c8bb3fda-110c-4d19-a457-864ad99242d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10968\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('có thể cho sinh viên đi thăm quan nhiều công ty xem quy mô và cách làm việc , để giúp hiểu rõ hơn vê ngành mình đang học .',\n",
              " 0)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test/sents.txt') as data, open('test/sentiments.txt') as label:\n",
        "  testdata = []\n",
        "  for dataline, labelline in zip(data, label):\n",
        "    sentence = dataline.strip()\n",
        "    sentiment = int(labelline.strip())\n",
        "    if sentiment == 1:\n",
        "      continue\n",
        "    testdata.append((sentence, sentiment))\n",
        "print(len(testdata))\n",
        "testdata[79]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M70mhK8p6zHM",
        "outputId": "a0c82543-c744-48fa-cb74-2e12d58b1ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('nhiệt tình giúp đỡ giải đáp những thắc mắc của sinh viên .', 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## phrase"
      ],
      "metadata": {
        "id": "fuOn7tEcLr62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "py_vncorenlp.download_model(save_dir='./')"
      ],
      "metadata": {
        "id": "zL05t3xVG-MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phraseModel = py_vncorenlp.VnCoreNLP(annotators=['wseg', 'pos'], save_dir='./')"
      ],
      "metadata": {
        "id": "5E48E1uM6ZVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getPos(sentence):\n",
        "  annotated = phraseModel.annotate_text(sentence)\n",
        "  words = [word['wordForm'] for word in annotated[0]]\n",
        "  tags = [word['posTag'] for word in annotated[0]]\n",
        "  return words, tags"
      ],
      "metadata": {
        "id": "wvhuVB_a77NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words, tags = getPos(traindata[999][0])\n",
        "print(words)\n",
        "print(tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uekbfbPJ8cJt",
        "outputId": "6c83f616-2618-47ed-985c-ec19968179b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cập_nhật', 'tài_liệu', 'đầy_đủ', 'cho', 'sinh_viên', '!']\n",
            "['V', 'N', 'A', 'E', 'N', 'CH']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getPhrase(words, tags):\n",
        "  phrases = []\n",
        "  ptags = []\n",
        "  for idx, word in enumerate(words):\n",
        "    phrase = tuple(words[idx:idx + 2])\n",
        "    ptag = tuple(tags[idx:idx + 2])\n",
        "    if ptag in [('N', 'A'), ('V', 'A'), ('R', 'A'), ('R', 'V'), ('V', 'R')]:\n",
        "      phrases.append(phrase)\n",
        "      ptags.append(ptag)\n",
        "  return phrases, ptags"
      ],
      "metadata": {
        "id": "16fdSX8G8tlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrases, ptags = getPhrase(words, tags)\n",
        "print(phrases)\n",
        "print(ptags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiEPiq8q9pa-",
        "outputId": "290ada7c-bf7f-40e0-b191-cde12bfd3124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('tài_liệu', 'đầy_đủ')]\n",
            "[('N', 'A')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pmi"
      ],
      "metadata": {
        "id": "qLVaadEcG8dA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PMIModel:\n",
        "  def __init__(self, traindata):\n",
        "    self.map1 = {}\n",
        "    self.map2 = {}\n",
        "    posCount = 0\n",
        "    globalCount = 0\n",
        "    for sentence, label in tqdm(traindata):\n",
        "      if label == 2:\n",
        "        posCount += 1\n",
        "      words, tags = getPos(sentence)\n",
        "      phrases, ptags = getPhrase(words, tags)\n",
        "      for p in phrases:\n",
        "        globalCount += 1\n",
        "        self.map1[p] = self.map1.get(p, 0) + 1\n",
        "        p2 = (p, label)\n",
        "        self.map2[p2] = self.map2.get(p2, 0) + 1\n",
        "    print(len(self.map1))\n",
        "    for key, val in self.map1.items():\n",
        "      self.map1[key] = val / globalCount\n",
        "    for key, val in self.map2.items():\n",
        "      self.map2[key] = val / globalCount\n",
        "    self.map1[0] = 1.0 - posCount / len(traindata)\n",
        "    self.map1[2] = posCount / len(traindata)\n",
        "\n",
        "  def getProb(self, p):\n",
        "    return self.map1.get(p, 0.0) + 0.01\n",
        "\n",
        "  def getProb2(self, p1, p2):\n",
        "    return self.map2.get((p1, p2), 0.0) + 0.01\n",
        "\n",
        "  def predict(self, sentence):\n",
        "    words, tags = getPos(sentence)\n",
        "    phrases, ptags = getPhrase(words, tags)\n",
        "    so = 0.0\n",
        "    for p in phrases:\n",
        "      sop2 = self.getProb2(p, 2) / (self.getProb(p) * self.getProb(2))\n",
        "      sop0 = self.getProb2(p, 0) / (self.getProb(p) * self.getProb(0))\n",
        "      so += math.log2(sop2) - math.log2(sop0)\n",
        "    return 2 if so >= 0 else 0\n",
        "\n",
        "  def test(self, dataset):\n",
        "    hitCount = 0\n",
        "    yTrue = []\n",
        "    yPred = []\n",
        "    for sentence, label in tqdm(dataset):\n",
        "      predict = self.predict(sentence)\n",
        "      yTrue.append(label)\n",
        "      yPred.append(predict)\n",
        "      if predict == label:\n",
        "        hitCount += 1\n",
        "    print(f'{hitCount}/{len(dataset)} ~{hitCount / len(dataset) * 100}')\n",
        "    f1Score = f1_score(yTrue, yPred, average='weighted')\n",
        "    print(f'f1 score: {f1Score}')"
      ],
      "metadata": {
        "id": "ABw9uaU2Eh3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pmiModel = PMIModel(traindata)\n",
        "pmiModel.test(testdata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtZSAsIxIOUz",
        "outputId": "06b10f67-9bbf-4695-eea6-49787a5b943c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10968/10968 [00:11<00:00, 984.06it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2999/2999 [00:02<00:00, 1202.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2163/2999 ~72.1240413471157\n",
            "f1 score: 0.7176818017124736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## word2vec"
      ],
      "metadata": {
        "id": "Ms08OSwNG-vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import torch\n",
        "import torch.nn.functional as torchF\n",
        "\n",
        "class W2VModel:\n",
        "  def __init__(self, traindata):\n",
        "    self.sentences = []\n",
        "    for sentence, label in tqdm(traindata):\n",
        "      words, tags = getPos(sentence)\n",
        "      self.sentences.append(words)\n",
        "    self.vectorSize = 100\n",
        "    self.w2v = Word2Vec(sentences=self.sentences, vector_size=self.vectorSize, window=5, min_count=1, workers=2)\n",
        "    print()\n",
        "    print(self.w2v.wv.vectors.shape)\n",
        "\n",
        "  def embed(self, word):\n",
        "    if word in self.w2v.wv.key_to_index:\n",
        "      return torch.Tensor(self.w2v.wv[word])\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "  def embed2(self, phrase):\n",
        "    res = torch.zeros(self.vectorSize)\n",
        "    resLen = 0\n",
        "    for word in phrase:\n",
        "      wres = self.embed(word)\n",
        "      if wres is None:\n",
        "        continue\n",
        "      res += wres\n",
        "      resLen += 1\n",
        "    return res / resLen\n",
        "\n",
        "  def predict(self, sentence):\n",
        "    posEp = self.embed('tốt')\n",
        "    negEp = self.embed('kém')\n",
        "    words, tags = getPos(sentence)\n",
        "    phrases, ptags = getPhrase(words, tags)\n",
        "    so = 0.0\n",
        "    for p in phrases:\n",
        "      ep = self.embed2(p)\n",
        "      posSim = torchF.cosine_similarity(ep, posEp, dim=0)\n",
        "      negSim = torchF.cosine_similarity(ep, negEp, dim=0)\n",
        "      so += posSim - negSim\n",
        "    return 2 if so >= 0 else 0\n",
        "\n",
        "  def test(self, dataset):\n",
        "    hitCount = 0\n",
        "    yTrue = []\n",
        "    yPred = []\n",
        "    for sentence, label in tqdm(dataset):\n",
        "      predict = self.predict(sentence)\n",
        "      yTrue.append(label)\n",
        "      yPred.append(predict)\n",
        "      if predict == label:\n",
        "        hitCount += 1\n",
        "    print(f'{hitCount}/{len(dataset)} ~{hitCount / len(dataset) * 100}')\n",
        "    f1Score = f1_score(yTrue, yPred, average='weighted')\n",
        "    print(f'f1 score: {f1Score}')"
      ],
      "metadata": {
        "id": "RWqpAP1uHAGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2vModel = W2VModel(traindata)\n",
        "w2vModel.test(testdata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FJiHbPbtGEZ",
        "outputId": "da1294ea-dabc-41ff-ccb2-3c7e580f0362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10968/10968 [00:09<00:00, 1147.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(3568, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2999 [00:00<?, ?it/s]<ipython-input-33-d97114ddf32d>:18: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  return torch.Tensor(self.w2v.wv[word])\n",
            "100%|██████████| 2999/2999 [00:03<00:00, 785.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2284/2999 ~76.15871957319106\n",
            "f1 score: 0.76117136121854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vLgUerFq8rW2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}