{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## requirement"
      ],
      "metadata": {
        "id": "9uyscYwuG0ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install py_vncorenlp gensim\n",
        "!pip install gdown==4.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-tTsdH66Isa",
        "outputId": "0afb4061-db86-4d3f-bfc0-7d4eb3c2fde3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: py_vncorenlp in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: pyjnius in /usr/local/lib/python3.10/dist-packages (from py_vncorenlp) (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Collecting gdown==4.6.0\n",
            "  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==4.6.0) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown==4.6.0) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown==4.6.0) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown==4.6.0) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==4.6.0) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==4.6.0) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.6.0) (2023.11.17)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.6.0) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "Successfully installed gdown-4.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import"
      ],
      "metadata": {
        "id": "3c8KW2WcG3c7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pbD5KQF_GKgQ"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import math\n",
        "import py_vncorenlp\n",
        "from sklearn.metrics import f1_score, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataset"
      ],
      "metadata": {
        "id": "YBvYkbmcG5nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir train\n",
        "!cd train && gdown https://drive.google.com/uc?id=1N41RpBMDfnMyipQUDTXoPvmPdd4ZDPuA&export=download\n",
        "!cd train && gdown https://drive.google.com/uc?id=16fOhp5N2xUSWCPfthUaSpbhtj8zKlCe0&export=download\n",
        "!mkdir test\n",
        "!cd test && gdown https://drive.google.com/uc?id=1jirCj9X_rLSoUFFvQD8RYY5GEC12va4-&export=download\n",
        "!cd test && gdown https://drive.google.com/uc?id=1RSOhUrtvT0A_DMcuugdpPyY2NwKvSK7C&export=download"
      ],
      "metadata": {
        "id": "-bljX-QzG7SE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84074808-c2d0-4fc5-b12a-28f3fc272c45"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘train’: File exists\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1N41RpBMDfnMyipQUDTXoPvmPdd4ZDPuA\n",
            "To: /content/train/sents.txt\n",
            "100% 898k/898k [00:00<00:00, 121MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16fOhp5N2xUSWCPfthUaSpbhtj8zKlCe0\n",
            "To: /content/train/sentiments.txt\n",
            "100% 22.9k/22.9k [00:00<00:00, 40.3MB/s]\n",
            "mkdir: cannot create directory ‘test’: File exists\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jirCj9X_rLSoUFFvQD8RYY5GEC12va4-\n",
            "To: /content/test/sents.txt\n",
            "100% 248k/248k [00:00<00:00, 79.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RSOhUrtvT0A_DMcuugdpPyY2NwKvSK7C\n",
            "To: /content/test/sentiments.txt\n",
            "100% 6.33k/6.33k [00:00<00:00, 14.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train/sents.txt') as data, open('train/sentiments.txt') as label:\n",
        "  traindata = []\n",
        "  for dataline, labelline in zip(data, label):\n",
        "    sentence = dataline.strip()\n",
        "    sentiment = int(labelline.strip())\n",
        "    if sentiment == 1:\n",
        "      continue\n",
        "    traindata.append((sentence, sentiment))\n",
        "print(len(traindata))\n",
        "traindata[12]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7UsyxeF_kw1",
        "outputId": "9b2b2d96-e15f-47b5-fa85-b8ce896a1474"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10968\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('có thể cho sinh viên đi thăm quan nhiều công ty xem quy mô và cách làm việc , để giúp hiểu rõ hơn vê ngành mình đang học .',\n",
              " 0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test/sents.txt') as data, open('test/sentiments.txt') as label:\n",
        "  testdata = []\n",
        "  for dataline, labelline in zip(data, label):\n",
        "    sentence = dataline.strip()\n",
        "    sentiment = int(labelline.strip())\n",
        "    if sentiment == 1:\n",
        "      continue\n",
        "    testdata.append((sentence, sentiment))\n",
        "print(len(testdata))\n",
        "testdata[79]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M70mhK8p6zHM",
        "outputId": "e553156b-372e-4d65-d476-1b65269753f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('nhiệt tình giúp đỡ giải đáp những thắc mắc của sinh viên .', 2)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## phrase"
      ],
      "metadata": {
        "id": "fuOn7tEcLr62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "py_vncorenlp.download_model(save_dir='./')"
      ],
      "metadata": {
        "id": "zL05t3xVG-MM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phraseModel = py_vncorenlp.VnCoreNLP(annotators=['wseg', 'pos'], save_dir='./')"
      ],
      "metadata": {
        "id": "5E48E1uM6ZVK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getPos(sentence):\n",
        "  annotated = phraseModel.annotate_text(sentence)\n",
        "  words = [word['wordForm'] for word in annotated[0]]\n",
        "  tags = [word['posTag'] for word in annotated[0]]\n",
        "  return words, tags"
      ],
      "metadata": {
        "id": "wvhuVB_a77NI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words, tags = getPos(traindata[999][0])\n",
        "print(words)\n",
        "print(tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uekbfbPJ8cJt",
        "outputId": "511d2deb-e4bd-415d-dd47-f461fc245b0f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cập_nhật', 'tài_liệu', 'đầy_đủ', 'cho', 'sinh_viên', '!']\n",
            "['V', 'N', 'A', 'E', 'N', 'CH']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getPhrase(words, tags):\n",
        "  phrases = []\n",
        "  ptags = []\n",
        "  for idx, word in enumerate(words):\n",
        "    phrase = tuple(words[idx:idx + 2])\n",
        "    ptag = tuple(tags[idx:idx + 2])\n",
        "    if ptag in [('N', 'A'), ('V', 'A'), ('R', 'A'), ('R', 'V'), ('V', 'R')]:\n",
        "      phrases.append(phrase)\n",
        "      ptags.append(ptag)\n",
        "  return phrases, ptags"
      ],
      "metadata": {
        "id": "16fdSX8G8tlj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrases, ptags = getPhrase(words, tags)\n",
        "print(phrases)\n",
        "print(ptags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiEPiq8q9pa-",
        "outputId": "f72ff0fc-3f39-49af-937c-050ac9c25561"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('tài_liệu', 'đầy_đủ')]\n",
            "[('N', 'A')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pmi"
      ],
      "metadata": {
        "id": "qLVaadEcG8dA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PMIModel:\n",
        "  def __init__(self, traindata):\n",
        "    self.map1 = {}\n",
        "    self.map2 = {}\n",
        "    posCount = 0\n",
        "    globalCount = 0\n",
        "    for sentence, label in tqdm(traindata):\n",
        "      if label == 2:\n",
        "        posCount += 1\n",
        "      words, tags = getPos(sentence)\n",
        "      phrases, ptags = getPhrase(words, tags)\n",
        "      for p in phrases:\n",
        "        globalCount += 1\n",
        "        self.map1[p] = self.map1.get(p, 0) + 1\n",
        "        p2 = (p, label)\n",
        "        self.map2[p2] = self.map2.get(p2, 0) + 1\n",
        "    print(len(self.map1))\n",
        "    for key, val in self.map1.items():\n",
        "      self.map1[key] = val / globalCount\n",
        "    for key, val in self.map2.items():\n",
        "      self.map2[key] = val / globalCount\n",
        "    self.map1[0] = 1.0 - posCount / len(traindata)\n",
        "    self.map1[2] = posCount / len(traindata)\n",
        "\n",
        "  def getProb(self, p):\n",
        "    return self.map1.get(p, 0.0) + 0.01\n",
        "\n",
        "  def getProb2(self, p1, p2):\n",
        "    return self.map2.get((p1, p2), 0.0) + 0.01\n",
        "\n",
        "  def predict(self, sentence):\n",
        "    words, tags = getPos(sentence)\n",
        "    phrases, ptags = getPhrase(words, tags)\n",
        "    so = 0.0\n",
        "    for p in phrases:\n",
        "      sop2 = self.getProb2(p, 2) / (self.getProb(p) * self.getProb(2))\n",
        "      sop0 = self.getProb2(p, 0) / (self.getProb(p) * self.getProb(0))\n",
        "      so += math.log2(sop2) - math.log2(sop0)\n",
        "    return 2 if so >= 0 else 0\n",
        "\n",
        "  def test(self, dataset):\n",
        "    hitCount = 0\n",
        "    yTrue = []\n",
        "    yPred = []\n",
        "    for sentence, label in tqdm(dataset):\n",
        "      predict = self.predict(sentence)\n",
        "      yTrue.append(label)\n",
        "      yPred.append(predict)\n",
        "      if predict == label:\n",
        "        hitCount += 1\n",
        "    print(f'{hitCount}/{len(dataset)} ~{hitCount / len(dataset) * 100}')\n",
        "    f1Score = f1_score(yTrue, yPred, average='weighted')\n",
        "    print(f'f1 score: {f1Score}')"
      ],
      "metadata": {
        "id": "ABw9uaU2Eh3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pmiModel = PMIModel(traindata)\n",
        "pmiModel.test(testdata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtZSAsIxIOUz",
        "outputId": "06b10f67-9bbf-4695-eea6-49787a5b943c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10968/10968 [00:11<00:00, 984.06it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2999/2999 [00:02<00:00, 1202.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2163/2999 ~72.1240413471157\n",
            "f1 score: 0.7176818017124736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## word2vec"
      ],
      "metadata": {
        "id": "Ms08OSwNG-vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import torch\n",
        "import torch.nn.functional as torchF\n",
        "\n",
        "class W2VModel:\n",
        "  def __init__(self, traindata):\n",
        "    self.sentences = []\n",
        "    for sentence, label in tqdm(traindata):\n",
        "      words, tags = getPos(sentence)\n",
        "      self.sentences.append(words)\n",
        "    self.vectorSize = 100\n",
        "    self.w2v = Word2Vec(sentences=self.sentences, vector_size=self.vectorSize, window=5, min_count=1, workers=2)\n",
        "    print()\n",
        "    print(self.w2v.wv.vectors.shape)\n",
        "\n",
        "  def embed(self, word):\n",
        "    if word in self.w2v.wv.key_to_index:\n",
        "      return torch.Tensor(self.w2v.wv[word])\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "  def embed2(self, phrase):\n",
        "    res = torch.zeros(self.vectorSize)\n",
        "    resLen = 0\n",
        "    for word in phrase:\n",
        "      wres = self.embed(word)\n",
        "      if wres is None:\n",
        "        continue\n",
        "      res += wres\n",
        "      resLen += 1\n",
        "    return res / resLen\n",
        "\n",
        "  def predict(self, sentence):\n",
        "    posEp = self.embed('tốt')\n",
        "    negEp = self.embed('kém')\n",
        "    words, tags = getPos(sentence)\n",
        "    phrases, ptags = getPhrase(words, tags)\n",
        "    so = 0.0\n",
        "    for p in phrases:\n",
        "      ep = self.embed2(p)\n",
        "      posSim = torchF.cosine_similarity(ep, posEp, dim=0)\n",
        "      negSim = torchF.cosine_similarity(ep, negEp, dim=0)\n",
        "      so += posSim - negSim\n",
        "    return 2 if so >= 0 else 0\n",
        "\n",
        "  def test(self, dataset):\n",
        "    hitCount = 0\n",
        "    yTrue = []\n",
        "    yPred = []\n",
        "    for sentence, label in tqdm(dataset):\n",
        "      predict = self.predict(sentence)\n",
        "      yTrue.append(label)\n",
        "      yPred.append(predict)\n",
        "      if predict == label:\n",
        "        hitCount += 1\n",
        "    print(f'{hitCount}/{len(dataset)} ~{hitCount / len(dataset) * 100}')\n",
        "    f1Score = f1_score(yTrue, yPred, average='weighted')\n",
        "    print(f'f1 score: {f1Score}')"
      ],
      "metadata": {
        "id": "RWqpAP1uHAGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2vModel = W2VModel(traindata)\n",
        "w2vModel.test(testdata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FJiHbPbtGEZ",
        "outputId": "da1294ea-dabc-41ff-ccb2-3c7e580f0362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10968/10968 [00:09<00:00, 1147.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(3568, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2999 [00:00<?, ?it/s]<ipython-input-33-d97114ddf32d>:18: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  return torch.Tensor(self.w2v.wv[word])\n",
            "100%|██████████| 2999/2999 [00:03<00:00, 785.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2284/2999 ~76.15871957319106\n",
            "f1 score: 0.76117136121854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## with neutral"
      ],
      "metadata": {
        "id": "EKSzqoQg_nv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train/sents.txt') as data, open('train/sentiments.txt') as label:\n",
        "  traindata = []\n",
        "  for dataline, labelline in zip(data, label):\n",
        "    sentence = dataline.strip()\n",
        "    sentiment = int(labelline.strip())\n",
        "    traindata.append((sentence, sentiment))\n",
        "print(len(traindata))\n",
        "traindata[12]"
      ],
      "metadata": {
        "id": "IAhd363iEpMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc687001-9832-49d7-e2e1-379e6cf30e21"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11426\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('đang dạy thầy wzjwz208 đi qua nước ngoài giữa chừng , thầy wzjwz209 dạy thay .',\n",
              " 1)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test/sents.txt') as data, open('test/sentiments.txt') as label:\n",
        "  testdata = []\n",
        "  for dataline, labelline in zip(data, label):\n",
        "    sentence = dataline.strip()\n",
        "    sentiment = int(labelline.strip())\n",
        "    testdata.append((sentence, sentiment))\n",
        "print(len(testdata))\n",
        "testdata[79]"
      ],
      "metadata": {
        "id": "0gu0waWBErH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504455b6-fc76-467a-a88a-8077656207b8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3166\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('giảng bài xúc tích .', 2)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PMIModel:\n",
        "  def __init__(self, traindata):\n",
        "    self.map1 = {}\n",
        "    self.map2 = {}\n",
        "    posCount = 0\n",
        "    globalCount = 0\n",
        "    for sentence, label in tqdm(traindata):\n",
        "      if label == 2:\n",
        "        posCount += 1\n",
        "      words, tags = getPos(sentence)\n",
        "      phrases, ptags = getPhrase(words, tags)\n",
        "      for p in phrases:\n",
        "        globalCount += 1\n",
        "        self.map1[p] = self.map1.get(p, 0) + 1\n",
        "        p2 = (p, label)\n",
        "        self.map2[p2] = self.map2.get(p2, 0) + 1\n",
        "    print(len(self.map1))\n",
        "    for key, val in self.map1.items():\n",
        "      self.map1[key] = val / globalCount\n",
        "    for key, val in self.map2.items():\n",
        "      self.map2[key] = val / globalCount\n",
        "    self.map1[0] = 1.0 - posCount / len(traindata)\n",
        "    self.map1[2] = posCount / len(traindata)\n",
        "\n",
        "  def getProb(self, p):\n",
        "    return self.map1.get(p, 0.0) + 0.01\n",
        "\n",
        "  def getProb2(self, p1, p2):\n",
        "    return self.map2.get((p1, p2), 0.0) + 0.01\n",
        "\n",
        "  def predict(self, sentence):\n",
        "    words, tags = getPos(sentence)\n",
        "    phrases, ptags = getPhrase(words, tags)\n",
        "    so = 0.0\n",
        "    for p in phrases:\n",
        "      sop2 = self.getProb2(p, 2) / (self.getProb(p) * self.getProb(2))\n",
        "      sop0 = self.getProb2(p, 0) / (self.getProb(p) * self.getProb(0))\n",
        "      so += math.log2(sop2) - math.log2(sop0)\n",
        "    if abs(so) <= 1e-8:\n",
        "      return 1\n",
        "    return 2 if so >= 0 else 0\n",
        "\n",
        "  def test(self, dataset):\n",
        "    hitCount = 0\n",
        "    yTrue = []\n",
        "    yPred = []\n",
        "    for sentence, label in tqdm(dataset):\n",
        "      predict = self.predict(sentence)\n",
        "      yTrue.append(label)\n",
        "      yPred.append(predict)\n",
        "      if predict == label:\n",
        "        hitCount += 1\n",
        "    print()\n",
        "    print(classification_report(yTrue, yPred, digits=4))"
      ],
      "metadata": {
        "id": "vLgUerFq8rW2"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pmiModel = PMIModel(traindata)\n",
        "pmiModel.test(testdata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Po1_dnh_qRL",
        "outputId": "784171ca-40ba-464c-8820-5f0232c3d25e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11426/11426 [00:10<00:00, 1104.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3166/3166 [00:03<00:00, 904.68it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8842    0.4173    0.5670      1409\n",
            "           1     0.1477    0.4431    0.2216       167\n",
            "           2     0.6450    0.8113    0.7187      1590\n",
            "\n",
            "    accuracy                         0.6166      3166\n",
            "   macro avg     0.5590    0.5573    0.5024      3166\n",
            "weighted avg     0.7252    0.6166    0.6250      3166\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import torch\n",
        "import torch.nn.functional as torchF\n",
        "\n",
        "class W2VModel:\n",
        "  def __init__(self, traindata):\n",
        "    self.sentences = []\n",
        "    for sentence, label in tqdm(traindata):\n",
        "      words, tags = getPos(sentence)\n",
        "      self.sentences.append(words)\n",
        "    self.vectorSize = 100\n",
        "    self.w2v = Word2Vec(sentences=self.sentences, vector_size=self.vectorSize, window=5, min_count=1, workers=2)\n",
        "    print()\n",
        "    print(self.w2v.wv.vectors.shape)\n",
        "\n",
        "  def embed(self, word):\n",
        "    if word in self.w2v.wv.key_to_index:\n",
        "      return torch.Tensor(self.w2v.wv[word])\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "  def embed2(self, phrase):\n",
        "    res = torch.zeros(self.vectorSize)\n",
        "    resLen = 0\n",
        "    for word in phrase:\n",
        "      wres = self.embed(word)\n",
        "      if wres is None:\n",
        "        continue\n",
        "      res += wres\n",
        "      resLen += 1\n",
        "    return res / resLen if resLen > 0 else res\n",
        "\n",
        "  def predict(self, sentence, posWord='tốt', negWord='kém'):\n",
        "    posEp = self.embed(posWord)\n",
        "    negEp = self.embed(negWord)\n",
        "    words, tags = getPos(sentence)\n",
        "    phrases, ptags = getPhrase(words, tags)\n",
        "    so = 0.0\n",
        "    for p in phrases:\n",
        "      ep = self.embed2(p)\n",
        "      posSim = torchF.cosine_similarity(ep, posEp, dim=0)\n",
        "      negSim = torchF.cosine_similarity(ep, negEp, dim=0)\n",
        "      so += posSim - negSim\n",
        "    if abs(so) <= 1e-8:\n",
        "      return 1\n",
        "    return 2 if so >= 0 else 0\n",
        "\n",
        "  def test(self, dataset, posWord='tốt', negWord='kém'):\n",
        "    hitCount = 0\n",
        "    yTrue = []\n",
        "    yPred = []\n",
        "    for sentence, label in tqdm(dataset):\n",
        "      predict = self.predict(sentence, posWord, negWord)\n",
        "      yTrue.append(label)\n",
        "      yPred.append(predict)\n",
        "      if predict == label:\n",
        "        hitCount += 1\n",
        "    print(f'{hitCount}/{len(dataset)} ~{hitCount / len(dataset) * 100}')\n",
        "    f1Score = f1_score(yTrue, yPred, average='weighted')\n",
        "    print(f'f1 score: {f1Score}')\n",
        "\n",
        "  def predict2(self, sentence, posList=['tốt'], negList=['kém']):\n",
        "    posEp = self.embed2(posList)\n",
        "    negEp = self.embed2(negList)\n",
        "    words, tags = getPos(sentence)\n",
        "    phrases, ptags = getPhrase(words, tags)\n",
        "    so = 0.0\n",
        "    for p in phrases:\n",
        "      ep = self.embed2(p)\n",
        "      posSim = torchF.cosine_similarity(ep, posEp, dim=0)\n",
        "      negSim = torchF.cosine_similarity(ep, negEp, dim=0)\n",
        "      so += posSim - negSim\n",
        "    if abs(so) <= 1e-8:\n",
        "      return 1\n",
        "    return 2 if so >= 0 else 0\n",
        "\n",
        "  def test2(self, dataset, posList=['tốt'], negList=['kém']):\n",
        "    hitCount = 0\n",
        "    yTrue = []\n",
        "    yPred = []\n",
        "    for sentence, label in tqdm(dataset):\n",
        "      predict = self.predict2(sentence, posList, negList)\n",
        "      yTrue.append(label)\n",
        "      yPred.append(predict)\n",
        "      if predict == label:\n",
        "        hitCount += 1\n",
        "    print()\n",
        "    print(classification_report(yTrue, yPred, digits=4))"
      ],
      "metadata": {
        "id": "HlAbnDF_Aebk"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2vModel = W2VModel(traindata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbLyvKZyzfr1",
        "outputId": "cf27e016-03ec-43f2-d209-d8e92d9ea43b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11426/11426 [00:10<00:00, 1134.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(3655, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2vModel.test2(testdata)"
      ],
      "metadata": {
        "id": "Z_lWH6lw5CUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48064461-6685-45f7-b0c7-eaedb70732c7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3166/3166 [00:03<00:00, 805.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6904    0.8197    0.7495      1409\n",
            "           1     0.1474    0.4431    0.2212       167\n",
            "           2     0.9092    0.5667    0.6982      1590\n",
            "\n",
            "    accuracy                         0.6728      3166\n",
            "   macro avg     0.5823    0.6098    0.5563      3166\n",
            "weighted avg     0.7716    0.6728    0.6959      3166\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2vModel.test2(testdata, ['hay'], ['tệ'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm73Q9oQ4Vh-",
        "outputId": "100d1e7f-8536-42c8-8f5d-7e3ca1c75984"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3166/3166 [00:04<00:00, 689.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6985    0.7480    0.7224      1409\n",
            "           1     0.1474    0.4431    0.2212       167\n",
            "           2     0.8294    0.6025    0.6980      1590\n",
            "\n",
            "    accuracy                         0.6589      3166\n",
            "   macro avg     0.5584    0.5979    0.5472      3166\n",
            "weighted avg     0.7352    0.6589    0.6837      3166\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2vModel.test2(testdata, ['vui'], ['chán'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij-fePNNzf4H",
        "outputId": "68444390-1c8c-434a-df66-c0242b1c1182"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3166/3166 [00:05<00:00, 567.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7143    0.8020    0.7556      1409\n",
            "           1     0.1474    0.4431    0.2212       167\n",
            "           2     0.8928    0.6075    0.7231      1590\n",
            "\n",
            "    accuracy                         0.6854      3166\n",
            "   macro avg     0.5848    0.6175    0.5666      3166\n",
            "weighted avg     0.7740    0.6854    0.7111      3166\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2vModel.test2(testdata, ['dễ'], ['khó'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTBRBbVw0G-o",
        "outputId": "72d78f7e-0181-4499-b314-9d40368ab721"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3166/3166 [00:04<00:00, 689.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8027    0.6295    0.7056      1409\n",
            "           1     0.1474    0.4431    0.2212       167\n",
            "           2     0.7569    0.7421    0.7494      1590\n",
            "\n",
            "    accuracy                         0.6762      3166\n",
            "   macro avg     0.5690    0.6049    0.5588      3166\n",
            "weighted avg     0.7451    0.6762    0.7021      3166\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2vModel.test2(testdata, ['tốt', 'hay', 'vui', 'dễ'], ['xấu', 'chán', 'khó', 'tệ'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CXBkCeh2E-i",
        "outputId": "a1f4cbec-be6c-4769-998c-0edb1710b861"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3166/3166 [00:04<00:00, 771.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7753    0.7225    0.7480      1409\n",
            "           1     0.1474    0.4431    0.2212       167\n",
            "           2     0.8238    0.7000    0.7569      1590\n",
            "\n",
            "    accuracy                         0.6965      3166\n",
            "   macro avg     0.5822    0.6219    0.5754      3166\n",
            "weighted avg     0.7666    0.6965    0.7247      3166\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xlN2yOEqGdAC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}